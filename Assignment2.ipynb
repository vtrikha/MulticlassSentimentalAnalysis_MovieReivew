{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment2_withResampling_After_Split.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "frivhPxlxkjH",
        "colab_type": "code",
        "outputId": "83a7c638-3dc4-4bfc-f32b-e6b14b2cb084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdHbMWx2xtbM",
        "colab_type": "code",
        "outputId": "9d736187-4d53-4037-e815-b91f585f0d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#import libraries\n",
        "import time\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "import string\n",
        "\n",
        "#for training\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "#for word\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxf2FLgxwrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url= 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "dataset = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNE30LGSzdMn",
        "colab_type": "code",
        "outputId": "375c991d-3b42-4b61-9a08-c42eae0f10c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3USla5o3zkN3",
        "colab_type": "code",
        "outputId": "6ac92941-8038-46f9-8204-097c4bb314f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB2iLll9zmVR",
        "colab_type": "code",
        "outputId": "11e05749-9102-4450-bae1-6d9825303c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dataset.isnull().values.any())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5wi4nRTR9xY",
        "colab_type": "code",
        "outputId": "59763804-20b2-4894-9aea-08dc3e93e832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "dataset['Sentiment'].value_counts()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLSoJh01jkCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset['Phrase'],dataset['Sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFvtfWS1kb1r",
        "colab_type": "code",
        "outputId": "b5c5402b-0425-473b-d57a-397f18f3405e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train.dropna\n",
        "X_test.dropna\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,)\n",
            "(46818,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWdTRJOt3fSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = True\n",
        "removePuncs = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hScCabPYJ45N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Preprocess_train_data=[]\n",
        "for x in range(0,len(X_train.values)):\n",
        "    tmpReview=[]\n",
        "    for w in nltk.word_tokenize(X_train.values[x]):\n",
        "        newWord = str(w).lower() #Set newWork to be the updated word\n",
        "        if remove_stopwords and (w in stopwords_en):#if the word is a stopword & we want to remove stopwords\n",
        "            continue #skip the word and don’t had it to the normalized review\n",
        "        if removePuncs and (w in punctuations):#if the word is a punc. & we want to remove punctuations\n",
        "            continue #skip the word and don’t had it to the normalized review\n",
        "        if useStemming: #if useStemming is set to True\n",
        "            #Keep one stemmer commented out\n",
        "            #newWord = porter.stem(newWord) #User porter stemmer\n",
        "            newWord = lancaster.stem(newWord) #Use Lancaster stemmer\n",
        "        if useLemma:\n",
        "            newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "        tmpReview.append(newWord) #Add normalized word to the tmp review\n",
        "    Preprocess_train_data.append(' '.join(tmpReview))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ62UqK0miHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Preprocess_test_data=[]\n",
        "for x in range(0,len(X_test.values)):\n",
        "    tmp_test_Review=[]\n",
        "    for w in nltk.word_tokenize(X_test.values[x]):\n",
        "        newWord = str(w).lower() #Set newWork to be the updated word\n",
        "        if remove_stopwords and (w in stopwords_en):#if the word is a stopword & we want to remove stopwords\n",
        "            continue #skip the word and don’t had it to the normalized review\n",
        "        if removePuncs and (w in punctuations):#if the word is a punc. & we want to remove punctuations\n",
        "            continue #skip the word and don’t had it to the normalized review\n",
        "        if useStemming: #if useStemming is set to True\n",
        "            #Keep one stemmer commented out\n",
        "            #newWord = porter.stem(newWord) #User porter stemmer\n",
        "            newWord = lancaster.stem(newWord) #Use Lancaster stemmer\n",
        "        if useLemma:\n",
        "            newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "        tmp_test_Review.append(newWord) #Add normalized word to the tmp review\n",
        "    Preprocess_test_data.append(' '.join(tmp_test_Review))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m5CAxFLOEa5",
        "colab_type": "code",
        "outputId": "e0aede88-4dfd-4906-b72e-dd0b9422e07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(Preprocess_train_data))\n",
        "len(Preprocess_test_data)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6VwvO9WOWde",
        "colab_type": "code",
        "outputId": "b7daa65b-6fac-4f2c-e8e2-39391c4c7822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoU5ZSP5PQe9",
        "colab_type": "code",
        "outputId": "7a27c4db-8973-41a5-d7b1-66714618d57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "Y_train.value_counts()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    55595\n",
              "3    23055\n",
              "1    19203\n",
              "4     6468\n",
              "0     4921\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU_m1NoJ-uTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "\n",
        "# Transform each text into a vector of word counts\n",
        "#vectorizer = CountVectorizer(stop_words=\"english\",ngram_range=(1, 1))\n",
        "#vectorizer_tfid = TfidfVectorizer(stop_words=\"english\",ngram_range=(1, 1))\n",
        "vectorizer_tfid = TfidfVectorizer(ngram_range=(1, 2),max_features=2000)\n",
        "\n",
        "#X = vectorizer_tfid.fit_transform(Preprocess_train_data)\n",
        "Y = dataset['Sentiment']\n",
        "Train_series = pd.Series(Preprocess_train_data)\n",
        "Test_series = pd.Series(Preprocess_test_data) \n",
        "x_train = vectorizer_tfid.fit_transform(Train_series)\n",
        "y_train = Y_train\n",
        "x_test = vectorizer_tfid.transform(Test_series)\n",
        "y_test = Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkFgNsEp9WF4",
        "colab_type": "code",
        "outputId": "15276559-0d68-4bd2-b860-4c5c50e3bef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape,x_test.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((109242, 2000), (46818, 2000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJNSxxrCfbdr",
        "colab_type": "code",
        "outputId": "62f17e4f-ca0e-4a62-8b4b-c9d52c843aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<109242x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 307234 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzJ00PoNBjHx",
        "colab_type": "code",
        "outputId": "5871acfc-2781-45d8-b3a0-3b07cf9165a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x_train_np = x_train.toarray()\n",
        "y_train_np = np.array(y_train)\n",
        "# Convert the testing data\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np = np.array(y_test)\n",
        "print(x_train_np.shape)\n",
        "print(y_train_np.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242, 2000)\n",
            "(109242,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBYyTi6sFDY5",
        "colab_type": "code",
        "outputId": "150dd98f-b93a-4e84-93d5-0bd289872a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x_train_np=x_train_np.reshape(x_train_np.shape[0],x_train_np.shape[1],1)\n",
        "x_test_np=x_test_np.reshape(x_test_np.shape[0],x_test_np.shape[1],1)\n",
        "print(x_train_np.shape)\n",
        "print(x_test_np.shape)\n",
        "\n",
        "y_train_np = to_categorical(y_train_np)\n",
        "print(y_train_np.shape)\n",
        "y_test_np = to_categorical(y_test_np)\n",
        "print(y_test_np.shape)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242, 2000, 1)\n",
            "(46818, 2000, 1)\n",
            "(109242, 5)\n",
            "(46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji7E9lZUDJy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bow_feature= pd.DataFrame(x_train_np, columns=vectorizer.get_feature_names())\n",
        "#bow_feature.head(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKoeXxupEmq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def recall_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true*y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0 ,1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true*y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0 ,1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "  precision = precision_m(y_true, y_pred)\n",
        "  recall = recall_m(y_true, y_pred)\n",
        "  return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi67svqLE0pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
        "from keras.layers import Activation, GlobalMaxPooling1D, AvgPool1D\n",
        "from keras import optimizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mY24H4yWwD0",
        "colab_type": "code",
        "outputId": "00f26f5f-9e98-48b3-bf9b-df758d04e07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(Dense(64,input_shape=(fea_matrix.shape[1],fea_matrix.shape[2])))\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(x_train_np.shape[1],x_train_np.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "#model.add(Flatten())\n",
        "model.add(Conv1D(filters=256, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=512, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(50, input_dim=2, activation='relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "#model.add(Activation('softplus'))\n",
        "model.summary()  \n",
        "#opt=adam(lr=0.0001, decay= 0.01)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_9 (Conv1D)            (None, 1999, 64)          192       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 999, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 998, 128)          16512     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 499, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 498, 256)          65792     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 249, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 248, 512)          262656    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 124, 512)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 63488)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               16253184  \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 5)                 325       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 16,639,813\n",
            "Trainable params: 16,639,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_sHMoCACmHo",
        "colab_type": "code",
        "outputId": "4cf6d4ee-acd7-4e14-c248-2146a51fef95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "history2= model.fit(x_train_np, y_train_np, epochs=50, verbose=1, validation_split=0.2, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 87393 samples, validate on 21849 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " 3456/87393 [>.............................] - ETA: 29:34 - loss: 1.3523 - acc: 0.4942 - f1_m: 0.2260 - precision_m: 0.4195 - recall_m: 0.1788"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCC1_m78EZ4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing results\n",
        "print(model.metrics_names)\n",
        "model.evaluate(x_test_np, y_test_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH4FkPzE-uQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history2.history['acc'])\n",
        "plt.plot(history2.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "#plt.show()\n",
        "plt.savefig('/content/drive/My Drive/NLP_prac/Subplot3.png', format='png', dpi=1200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDkxa2saGAlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olYmXR6sBy9H",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}